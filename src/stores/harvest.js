import { defineStore } from 'pinia';
import { useAuthStore } from './auth';
import { useArchiveStore } from './archiveStore';
import { useCollaborationStore } from './collaborationStore';
import { useItineraryStore } from './itineraryStore';
import { addToSyncQueue } from '@/services/archiveSyncQueue';

import { safeDeepClone, setLocalStorageCache, getLocalStorageCache, removeFromAllCaches } from '@/services/cacheManager';
import { apiInterceptor } from '@/services/apiInterceptor';
import api from '@/services/api';
import logger from '@/utils/logger.js';
import localforage from 'localforage';
import { supabase } from '@/supabase';
import { TimeService } from '@/utils/time';
import { withTimeout } from '@/utils/promiseUtils';

const HARVEST_ROWS_KEY = 'harvest_rows';

export const useHarvestStore = defineStore('harvest', {
  state: () => ({
    // Local State
    rows: [],
    masterLimit: 100000,
    extraLimit: 0,
    currentBalance: 0,
    isLoading: false,
    isModified: false,

    // Shared State
    sharedRows: [],
    sharedMasterLimit: 0,
    sharedExtraLimit: 0,
    sharedCurrentBalance: 0,
    sharedLastUpdated: null,
    sharedRole: 'viewer', // Track role for shared session
    currentSharedUserId: null,
    isSharedLoading: false,

    // General
    currentDate: new Date().toISOString().split('T')[0],
    error: null,
    searchQuery: '',
    realtimeChannel: null, // For shared session
    ownRealtimeChannel: null, // For my own session (Admin sync)
    autoSyncInterval: null, // For periodic auto-sync of shared sessions
    isCloudSyncing: false,
  }),

  getters: {
    // --- Local Getters ---
    totals: (state) => {
      const rows = state.rows || [];
      return rows.reduce((acc, row) => {
        acc.amount += parseFloat(row.amount) || 0;
        acc.extra += parseFloat(row.extra) || 0;
        acc.collector += parseFloat(row.collector) || 0;
        acc.net += parseFloat(row.net) || 0;
        return acc;
      }, { amount: 0, extra: 0, collector: 0, net: 0 });
    },

    customerCount: (state) => {
      return (state.rows || []).filter(row => row.shop && row.shop.trim() !== '').length;
    },

    hasData: (state) => {
      if (!state.rows || state.rows.length === 0) return false;
      if (state.rows.length > 1) return true;
      const firstRow = state.rows[0];
      return !!(firstRow.shop || firstRow.code || firstRow.amount || firstRow.collector || firstRow.extra);
    },

    resetStatus: (state) => {
      const totalCollected = state.totals.collector || 0;
      const resetVal = (state.currentBalance || 0) - ((state.masterLimit || 0) + (state.extraLimit || 0));
      const combinedValue = totalCollected + resetVal;

      if (combinedValue === 0) return { val: combinedValue, text: 'ÿ™ŸÖ ÿßŸÑÿ™ÿ≠ÿµŸäŸÑ ÿ®ŸÜÿ¨ÿßÿ≠ ‚úÖ', color: '#10b981' };
      if (combinedValue < 0) return { val: combinedValue, text: 'ÿπÿ¨ÿ≤ üî¥', color: '#ef4444' };
      return { val: combinedValue, text: 'ÿ≤ŸäÿßÿØÿ© üîµ', color: '#3b82f6' };
    },

    resetAmount: (state) => (parseFloat(state.currentBalance) || 0) - ((parseFloat(state.masterLimit) || 0) + (parseFloat(state.extraLimit) || 0)),

    totalNet: (state) => state.totals.collector - (state.totals.amount + state.totals.extra),

    // --- Shared Getters ---
    sharedTotals: (state) => {
      const rows = state.sharedRows || [];
      return rows.reduce((acc, row) => {
        acc.amount += parseFloat(row.amount) || 0;
        acc.extra += parseFloat(row.extra) || 0;
        acc.collector += parseFloat(row.collector) || 0;
        acc.net += parseFloat(row.net) || 0;
        return acc;
      }, { amount: 0, extra: 0, collector: 0, net: 0 });
    },
  },

  actions: {
    async initialize() {
      // This function ONLY loads local data. Shared data is handled by switchToUserSession.
      const authStore = useAuthStore();
      this.isLoading = true;
      try {
        await this.loadMasterLimit(); // From localStorage
        await this.loadExtraLimit(); // From localStorage
        const savedBalance = await getLocalStorageCache('currentBalance');
        if (savedBalance) this.currentBalance = parseFloat(savedBalance);

        const hasImportedData = await this.loadDataFromStorage();
        if (!hasImportedData) {
          const savedRows = await localforage.getItem(HARVEST_ROWS_KEY);
          if (savedRows && Array.isArray(savedRows)) {
            this.rows = savedRows;
          } else {
            await this.resetTable();
          }
        }

        // Start listening for Admin overrides or other sync events
        this.initOwnRealtimeSubscription();

        // Initial Cloud Sync
        if (navigator.onLine && authStore.user) {
          if (!hasImportedData) {
            this.syncFromCloud().catch(() => { });
          }
          // Also broadcast our current state so others (admins) see us as online
          this.forceSyncToCloud(authStore.user.id).catch(() => { });
        }

      } catch (err) {
        logger.error('Harvest initialization failed:', err);
        await this.resetTable();
      } finally {
        this.isLoading = false;
      }
    },

    async resetTable() {
      this.rows = [{ id: Date.now(), shop: '', code: '', amount: '', extra: '', collector: '', net: 0, hasOverdue: false, hasOverpayment: false }];
      await this.saveRowsToStorage();
    },

    async saveRowsToStorage(skipCloud = false) {
      // This function ONLY saves the local `rows` to localforage.
      try {
        const cleanedRows = safeDeepClone(this.rows);
        await localforage.setItem(HARVEST_ROWS_KEY, cleanedRows);
        this.isModified = true;

        const authStore = useAuthStore();
        if (!skipCloud && navigator.onLine && authStore.user) {
          this.syncToCloud(authStore.user.id).catch(err => {
            logger.warn('Cloud sync for local data skipped:', err.message);
          });
        }
      } catch (error) {
        logger.error('Error saving local rows to storage:', error);
      }
    },

    /**
     * ÿ™ÿ≠ÿ∂Ÿäÿ± ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ ŸÇÿ®ŸÑ ÿßŸÑÿ™ÿ≠ÿØŸäÿ´ - ÿ≠ŸÅÿ∏ ÿ¨ŸÖŸäÿπ ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ ÿßŸÑÿ≠ÿ±ÿ¨ÿ©
     * Ÿäÿ™ŸÖ ÿßÿ≥ÿ™ÿØÿπÿßÿ§Ÿáÿß ŸÇÿ®ŸÑ ÿ™ÿ≠ÿØŸäÿ´ Service Worker ŸÑÿ∂ŸÖÿßŸÜ ÿπÿØŸÖ ŸÅŸÇÿØÿßŸÜ ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™
     */
    async prepareForUpdate() {
      logger.info('üíæ Preparing for update - saving all critical data...');

      try {
        // 1. ÿ≠ŸÅÿ∏ ÿßŸÑÿµŸÅŸàŸÅ ÿßŸÑÿ≠ÿßŸÑŸäÿ©
        const cleanedRows = safeDeepClone(this.rows);
        await localforage.setItem(HARVEST_ROWS_KEY, cleanedRows);
        logger.info('‚úÖ Saved harvest rows');

        // 2. ÿ≠ŸÅÿ∏ ÿßŸÑÿ•ÿπÿØÿßÿØÿßÿ™ ŸÅŸä localStorage
        await Promise.all([
          setLocalStorageCache('masterLimit', String(this.masterLimit)),
          setLocalStorageCache('extraLimit', String(this.extraLimit)),
          setLocalStorageCache('currentBalance', String(this.currentBalance))
        ]);
        logger.info('‚úÖ Saved limits and balance');

        // 3. ÿßŸÑÿ™ÿ£ŸÉÿØ ŸÖŸÜ ÿ≠ŸÅÿ∏ ÿ®ŸäÿßŸÜÿßÿ™ ÿßŸÑŸÖÿ™ÿ£ÿÆÿ±ÿßÿ™ ÿ•ÿ∞ÿß ŸÉÿßŸÜÿ™ ŸÖŸàÿ¨ŸàÿØÿ©
        const overdueMetadata = await localforage.getItem('overdue_stores_metadata');
        if (overdueMetadata && overdueMetadata.items && overdueMetadata.items.length > 0) {
          // ÿ•ÿπÿßÿØÿ© ÿ≠ŸÅÿ∏Ÿáÿß ŸÑŸÑÿ™ÿ£ŸÉÿØ ŸÖŸÜ ÿßÿ≥ÿ™ŸÖÿ±ÿßÿ±Ÿäÿ™Ÿáÿß
          await localforage.setItem('overdue_stores_metadata', overdueMetadata);
          logger.info(`‚úÖ Verified overdue metadata (${overdueMetadata.items.length} items)`);
        }

        // 4. ŸÖÿ≠ÿßŸàŸÑÿ© ÿßŸÑŸÖÿ≤ÿßŸÖŸÜÿ© ÿßŸÑÿ≥ÿ≠ÿßÿ®Ÿäÿ© ÿ•ÿ∞ÿß ŸÉÿßŸÜ ŸÖÿ™ÿµŸÑÿßŸã
        const authStore = useAuthStore();
        if (navigator.onLine && authStore.user) {
          try {
            await this.syncToCloud(authStore.user.id);
            logger.info('‚úÖ Synced to cloud before update');
          } catch (syncErr) {
            logger.warn('‚ö†Ô∏è Cloud sync failed, but local data is saved:', syncErr.message);
            // ŸÑÿß ŸÜŸÅÿ¥ŸÑ ÿßŸÑÿπŸÖŸÑŸäÿ© ÿ•ÿ∞ÿß ŸÅÿ¥ŸÑÿ™ ÿßŸÑŸÖÿ≤ÿßŸÖŸÜÿ© ÿßŸÑÿ≥ÿ≠ÿßÿ®Ÿäÿ©
          }
        }

        logger.info('‚úÖ All data prepared successfully for update');
        return { success: true };

      } catch (error) {
        logger.error('‚ùå Failed to prepare data for update:', error);
        throw error;
      }
    },

    // New: Fetch latest state from cloud
    async syncFromCloud() {
      const authStore = useAuthStore();
      if (!authStore.user) return;
      const userId = authStore.user.id;

      // Wrap with timeout to prevent hanging during initial load (Increased to 15s)
      const { data, error } = await withTimeout(
        (signal) => supabase
          .from('live_harvest')
          .select('*')
          .eq('user_id', userId)
          .maybeSingle()
          .abortSignal(signal),
        20000,
        'Cloud sync (read) timed out'
      );

      if (data) {
        // Check if cloud is newer than local? 
        // For cooperation, we assume Cloud is the "Meeting Point".
        // But purely local work might be newer if offline? 
        // If we are initializing, we just loaded from Local.
        // Let's assume Cloud wins if it has content, OR we check timestamps if we had them.
        // Since we don't track local-only timestamp reliably, we'll assume Cloud is Master for Collaboration.
        // BUT be careful not to overwrite Unsynced Local work.
        // "syncToCloud" is called on every save. So if I was offline, I have unsynced work.
        // If I come online, "syncFromCloud" runs.
        // Ideally, we should syncToCloud pending changes first?
        // Since we don't have a sophisticated conflict resolution, and the User didn't ask for "Offline Sync Conflict Resolution",
        // I will prioritizing NOT overwriting if I have local data?
        // Actually, for "Live Cooperation", checking Cloud is better.
        // Let's just update if differ.

        // Optimization: If rows are empty locally but exist in cloud, definitely take cloud.
        const localEmpty = !this.hasData;

        if (localEmpty || (data.updated_at && new Date(data.updated_at) > new Date(Date.now() - 60000))) {
          // If cloud data is very recent (last minute) or local is empty, take it.
          // This is a heuristic.
          this.rows = data.rows || [];
          this.masterLimit = parseFloat(data.master_limit) || 0;
          this.extraLimit = parseFloat(data.extra_limit) || 0;
          this.currentBalance = parseFloat(data.current_balance) || 0;
          logger.info('‚òÅÔ∏è Applied Initial Cloud Data');

          // Fix: Clone before saving to avoid DataCloneError with Proxies
          const rowsToSave = safeDeepClone(this.rows);
          await localforage.setItem(HARVEST_ROWS_KEY, rowsToSave);
        }
      }
    },

    // Syncs LOCAL data to the cloud for the logged-in user.
    async syncToCloud(targetUserId) {
      if (!targetUserId) return;
      this.isCloudSyncing = true;
      try {
        const payload = {
          user_id: targetUserId,
          rows: this.rows,
          master_limit: this.masterLimit,
          extra_limit: this.extraLimit,
          current_balance: this.currentBalance,
          last_updated_by: (await supabase.auth.getUser()).data.user?.id,
          updated_at: new Date()
        };

        const { error } = await withTimeout(
          (signal) => supabase.from('live_harvest').upsert(payload, { onConflict: 'user_id' }).abortSignal(signal),
          15000,
          'Cloud sync timed out'
        );

        if (error) throw error;
      } catch (error) {
        logger.warn('Sync local data to cloud failed:', error.message);
      } finally {
        this.isCloudSyncing = false;
      }
    },



    async updateSharedData(targetUserId) {
      if (!targetUserId) return;
      this.isCloudSyncing = true;

      try {
        const authStore = useAuthStore();
        const payload = {
          rows: this.sharedRows,
          master_limit: this.sharedMasterLimit,
          extra_limit: this.sharedExtraLimit,
          current_balance: this.sharedCurrentBalance,
          last_updated_by: authStore.user?.id, // Track who updated it
          updated_at: new Date()
        };

        logger.debug(`üíæ Syncing shared data for target: ${targetUserId}...`);

        const { error } = await withTimeout(
          (signal) => supabase
            .from('live_harvest')
            .update(payload)
            .eq('user_id', targetUserId)
            .abortSignal(signal),
          15000,
          'Shared data update timed out'
        );

        if (error) throw error;
      } catch (error) {
        logger.error('Failed to update shared data:', error.message);
      } finally {
        this.isCloudSyncing = false;
      }
    },

    async switchToUserSession(userId) {
      // If we are already loading THIS specific session, ignore.
      // If it's a DIFFERENT session, we allow the switch to proceed.
      if (this.isSharedLoading && this.currentSharedUserId === userId) {
        return;
      }

      this.isSharedLoading = true;
      this.currentSharedUserId = userId; // Set early to track intent

      // CRITICAL: This function now only affects the SHARED part of the state.

      // Clear existing realtime channel
      if (this.realtimeChannel) {
        await supabase.removeChannel(this.realtimeChannel);
        this.realtimeChannel = null;
      }

      // Clear existing auto-sync timeout
      if (this.autoSyncInterval) {
        clearTimeout(this.autoSyncInterval);
        this.autoSyncInterval = null;
      }

      if (!userId) {
        this.sharedRows = [];
        this.sharedMasterLimit = 0;
        this.sharedExtraLimit = 0;
        this.sharedCurrentBalance = 0;
        this.currentSharedUserId = null;
        this.isSharedLoading = false;
        return;
      }

      this.currentSharedUserId = userId;

      // Function to fetch shared data
      const fetchSharedData = async (isBackground = false) => {
        // Skip fetch if browser is offline
        if (typeof navigator !== 'undefined' && !navigator.onLine) {
          if (!isBackground) logger.warn('üåê Skipping fetch: Browser is offline');
          return;
        }

        try {
          const { data, error } = await supabase
            .from('live_harvest')
            .select('*')
            .eq('user_id', userId)
            .maybeSingle();

          if (error && error.code !== 'PGRST116') throw error;

          if (data) {
            this.sharedRows = data.rows || [];
            this.sharedMasterLimit = parseFloat(data.master_limit) || 0;
            this.sharedExtraLimit = parseFloat(data.extra_limit) || 0;
            this.sharedCurrentBalance = parseFloat(data.current_balance) || 0;
            this.sharedLastUpdated = data.updated_at || null;
          } else {
            // If no data exists for the user, reset the shared state.
            this.sharedRows = [];
            this.sharedMasterLimit = 0;
            this.sharedExtraLimit = 0;
            this.sharedCurrentBalance = 0;
            this.sharedLastUpdated = null;
          }
        } catch (err) {
          // Identify network-related fetch errors that are likely transient
          const isNetworkError = err?.message === 'Failed to fetch' ||
            err?.message?.includes('net::ERR_') ||
            !navigator.onLine;

          if (isNetworkError) {
            if (!isBackground) logger.warn('üåê Network temporary issue while fetching shared data');
            // Background polling errors stay silent to avoid console noise
          } else {
            logger.error('Failed to fetch shared data:', err);
          }
        }
      };

      try {
        // Initial fetch with timeout and ONE retry
        // This handles cases where the first request fails due to cold start or stale connection
        let attempt = 0;
        const maxAttempts = 2;

        while (attempt < maxAttempts) {
          try {
            attempt++;
            await Promise.race([
              fetchSharedData(),
              new Promise((_, reject) => setTimeout(() => reject(new Error('Fetch timeout')), 10000)) // 10s per attempt
            ]);
            break; // Success
          } catch (err) {
            if (attempt >= maxAttempts) throw err;
            logger.warn(`‚ö†Ô∏è Fetch shared data attempt ${attempt} failed, retrying...`);
            await new Promise(r => setTimeout(r, 1000)); // Wait 1s before retry
          }
        }

        // Setup realtime subscription
        this.realtimeChannel = supabase
          .channel(`harvest-${userId}`)
          .on(
            'postgres_changes',
            { event: '*', schema: 'public', table: 'live_harvest', filter: `user_id=eq.${userId}` },
            (payload) => {
              const newData = payload.new || payload.old;
              if (newData) {
                // ECHO PREVENTION
                const authStore = useAuthStore();
                if (newData.last_updated_by === authStore.user?.id) return;

                if (payload.eventType === 'DELETE') {
                  this.sharedRows = [];
                  return;
                }

                // Update shared data on the fly.
                this.sharedRows = newData.rows || [];
                this.sharedMasterLimit = parseFloat(newData.master_limit) || 0;
                this.sharedExtraLimit = parseFloat(newData.extra_limit) || 0;
                this.sharedCurrentBalance = parseFloat(newData.current_balance) || 0;
                this.sharedLastUpdated = newData.updated_at || new Date().toISOString();
                logger.info('üì° Realtime change received for shared session');
              }
            }
          )
          .subscribe();

        // Setup periodic auto-sync every 30 seconds using recursive timeout for safety
        const scheduleNextSync = () => {
          this.autoSyncInterval = setTimeout(async () => {
            // Only proceed if we still care about this specific session
            if (this.currentSharedUserId === userId) {
              await fetchSharedData(true);
              scheduleNextSync();
            }
          }, 30000);
        };
        scheduleNextSync();

        logger.info('‚úÖ Shared session initialized with realtime + auto-sync');

      } catch (err) {
        logger.error('Failed to switch to user session:', err);
        // On failure, clear the shared state, don't touch local data.
        this.sharedRows = [];
        this.sharedMasterLimit = 0;
        this.sharedExtraLimit = 0;
        this.sharedCurrentBalance = 0;
        this.sharedLastUpdated = null;
        this.currentSharedUserId = null;
      } finally {
        this.isSharedLoading = false;
      }
    },

    // --- Bidirectional Sync for Owner ---
    async initOwnRealtimeSubscription() {
      const auth = useAuthStore();
      if (!auth.user) return;

      const userId = auth.user.id;

      if (this.ownRealtimeChannel) {
        supabase.removeChannel(this.ownRealtimeChannel);
      }

      this.ownRealtimeChannel = supabase
        .channel(`my-harvest-sync-${userId}`)
        .on(
          'postgres_changes',
          { event: 'UPDATE', schema: 'public', table: 'live_harvest', filter: `user_id=eq.${userId}` },
          (payload) => {
            const newData = payload.new;
            if (!newData) return;

            // CRITICAL: Check who updated it.
            // If I updated it (last_updated_by == my_id), ignore it to avoid loops/jitter.
            if (newData.last_updated_by === userId) return;

            // If someone else (e.g. Admin) updated it, apply changes to LOCAL state.
            this.rows = newData.rows || [];
            this.masterLimit = parseFloat(newData.master_limit) || 0;
            this.extraLimit = parseFloat(newData.extra_limit) || 0;
            this.currentBalance = parseFloat(newData.current_balance) || 0;

            // We should also persist to local storage to keep offline capability in sync
            // IMPORTANT: skipCloud=true to prevent pushing back the same data
            this.saveRowsToStorage(true);

            logger.info('Received update from Admin/Collaborator - synced automatically');
          }
        )
        .subscribe();
    },



    async reconnectRealtime() {
      const auth = useAuthStore();
      if (!auth.user) return;

      logger.info('üîå Reconnecting Harvest Realtime...');

      // 1. Own subscription
      this.initOwnRealtimeSubscription();

      // 2. Shared subscription if active
      if (this.currentSharedUserId) {
        logger.info(`üîå Reconnecting Shared Realtime for user: ${this.currentSharedUserId}...`);
        // We can re-use switchToUserSession logic but skipping fetch if possible? 
        // Actually, just calling switchToUserSession again is the most robust way to ensure everything (fetch + real-time) is back in sync.
        // It handles its own cleanup.
        // But we want to avoid full loading state flicker if possible?
        // Let's just re-subscribe the channel manually to avoid UI flicker.

        const userId = this.currentSharedUserId;
        if (this.realtimeChannel) await supabase.removeChannel(this.realtimeChannel);

        this.realtimeChannel = supabase
          .channel(`harvest-${userId}`)
          .on(
            'postgres_changes',
            { event: 'UPDATE', schema: 'public', table: 'live_harvest', filter: `user_id=eq.${userId}` },
            (payload) => {
              const newData = payload.new;
              if (newData) {
                this.sharedRows = newData.rows;
                this.sharedMasterLimit = parseFloat(newData.master_limit) || 0;
                this.sharedExtraLimit = parseFloat(newData.extra_limit) || 0;
                this.sharedCurrentBalance = parseFloat(newData.current_balance) || 0;
                this.sharedLastUpdated = newData.updated_at || new Date().toISOString();
                logger.info('üì° Realtime update received for shared session (Reconnected)');
              }
            }
          )
          .subscribe();
      }
    },

    async forceSyncToCloud(targetUserId) {
      return this.syncToCloud(targetUserId);
    },

    /**
     * ÿ≠ŸÅÿ∏ ÿßŸÑŸÖÿ™ÿ£ÿÆÿ±ÿßÿ™ ŸÖÿπ ÿ™ÿßÿ±ŸäÿÆ ÿßŸÑÿ£ÿ±ÿ¥ŸäŸÅ
     * @param {Array} overdueItems - ÿßŸÑŸÖÿ™ÿ£ÿÆÿ±ÿßÿ™
     * @param {String} archiveDate - ÿ™ÿßÿ±ŸäÿÆ ÿßŸÑÿ£ÿ±ÿ¥ŸäŸÅ
     */
    async _saveOverdueWithArchiveDate(overdueItems, archiveDate) {
      // ‚úÖ ÿ≠ÿ∞ŸÅ ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ ÿßŸÑŸÇÿØŸäŸÖÿ© ÿ£ŸàŸÑÿßŸã (ŸÉŸÑÿß ÿßŸÑŸÜÿ∏ÿßŸÖŸäŸÜ)
      await Promise.all([
        localforage.removeItem('overdue_stores'),          // ÿßŸÑŸÜÿ∏ÿßŸÖ ÿßŸÑŸÇÿØŸäŸÖ
        localforage.removeItem('overdue_stores_metadata')  // ÿßŸÑŸÜÿ∏ÿßŸÖ ÿßŸÑÿ¨ÿØŸäÿØ
      ]);

      logger.info('üóëÔ∏è Cleared old overdue data locally (both formats)');

      // ‚úÖ ÿ≠ŸÅÿ∏ ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ ÿßŸÑÿ¨ÿØŸäÿØÿ©
      const metadata = {
        archive_date: archiveDate,
        created_at: new Date().toISOString(),
        synced_to_cloud: false,
        items: overdueItems
      };

      await localforage.setItem('overdue_stores_metadata', metadata);
      logger.info(`üíæ Saved ${overdueItems.length} overdue items for archive date: ${archiveDate}`);
    },

    /**
     * ÿßŸÑÿ≠ÿµŸàŸÑ ÿπŸÑŸâ ÿ¢ÿÆÿ± ÿ™ÿßÿ±ŸäÿÆ ÿ£ÿ±ÿ¥ŸäŸÅ
     * @returns {String|null} ÿ¢ÿÆÿ± ÿ™ÿßÿ±ŸäÿÆ ÿ£ÿ±ÿ¥ŸäŸÅ ÿ£Ÿà null
     */
    async _getLatestArchiveDate() {
      const archiveStore = useArchiveStore();

      // ÿ¨ŸÑÿ® ÿßŸÑÿ™Ÿàÿßÿ±ŸäÿÆ ÿßŸÑŸÖÿ™ÿßÿ≠ÿ© ÿ•ÿ∞ÿß ŸÑŸÖ ÿ™ŸÉŸÜ ŸÖÿ≠ŸÖŸÑÿ©
      if (archiveStore.availableDates.length === 0) {
        await archiveStore.loadAvailableDates();
      }

      // ÿ¢ÿÆÿ± ÿ™ÿßÿ±ŸäÿÆ ŸáŸà ÿßŸÑÿ£ŸàŸÑ ŸÅŸä ÿßŸÑŸÇÿßÿ¶ŸÖÿ© (ŸÖÿ±ÿ™ÿ®ÿ© ÿ™ŸÜÿßÿ≤ŸÑŸäÿßŸã)
      const latestDate = archiveStore.availableDates[0]?.value || null;

      logger.info(`üìÖ Latest archive date: ${latestDate || 'none'}`);
      return latestDate;
    },

    // ÿØÿßŸÑÿ© ÿÆÿßÿµÿ© ŸÑŸÖÿ≤ÿßŸÖŸÜÿ© ÿßŸÑŸÖÿ™ÿ£ÿÆÿ±ÿßÿ™ ÿ≥ÿ≠ÿßÿ®ŸäÿßŸã (ÿ≠ÿ∞ŸÅ ÿßŸÑŸÇÿØŸäŸÖ Ÿàÿ•ÿ∂ÿßŸÅÿ© ÿßŸÑÿ¨ÿØŸäÿØ)
    async syncOverdueStoresToCloud(overdueItems, archiveDate, skipQueueOnError = false) {
      const authStore = useAuthStore();

      if (!authStore.user) {
        logger.warn('‚ö†Ô∏è Cannot sync overdue: No authenticated user');
        return;
      }

      if (!navigator.onLine) {
        logger.warn('‚ö†Ô∏è Cannot sync overdue: Offline');
        if (!skipQueueOnError) {
          await addToSyncQueue({
            type: 'sync_overdue_stores',
            payload: { items: overdueItems, archive_date: archiveDate },
            timestamp: Date.now()
          });
        }
        return;
      }

      try {
        const userId = authStore.user.id;

        // 1. Delete all existing pending overdue stores for this user
        const { error: deleteError } = await supabase
          .from('pending_overdue_stores')
          .delete()
          .eq('user_id', userId);

        if (deleteError) throw deleteError;

        logger.info('üóëÔ∏è Deleted all old overdue stores from cloud');

        // 2. If we have new items, insert them
        if (overdueItems && overdueItems.length > 0) {
          const records = overdueItems.map(item => ({
            user_id: userId,
            shop: item.shop,
            code: item.code,
            net: item.net,
            archive_date: archiveDate  // ‚Üê ÿ•ÿ∂ÿßŸÅÿ© ÿßŸÑÿ™ÿßÿ±ŸäÿÆ
          }));

          const { error: insertError } = await supabase
            .from('pending_overdue_stores')
            .insert(records);

          if (insertError) throw insertError;

          logger.info(`‚òÅÔ∏è Synced ${overdueItems.length} overdue items to cloud with date: ${archiveDate}`);
        } else {
          logger.info('‚òÅÔ∏è No overdue items to sync (all cleared)');
        }

      } catch (err) {
        logger.error('‚ùå Failed to sync overdue stores to cloud:', err);

        // ŸÅŸä ÿ≠ÿßŸÑÿ© ÿßŸÑŸÅÿ¥ŸÑÿå ÿ•ÿ∂ÿßŸÅÿ© ŸÑŸÑÿ∑ÿßÿ®Ÿàÿ± ÿ•ÿ∞ÿß ŸÑŸÖ Ÿäÿ∑ŸÑÿ® ÿ™ÿÆÿ∑Ÿä ÿ∞ŸÑŸÉ
        if (!skipQueueOnError) {
          await addToSyncQueue({
            type: 'sync_overdue_stores',
            payload: { items: overdueItems, archive_date: archiveDate },
            timestamp: Date.now()
          });
        }

        throw err; // Re-throw to be caught by caller if needed
      }
    },

    /**
     * ÿ¨ŸÑÿ® ÿßŸÑŸÖÿ™ÿ£ÿÆÿ±ÿßÿ™ - ŸÖŸÜÿ∑ŸÇ ŸÖÿ®ÿ≥ÿ∑ ÿ®ŸÜÿßÿ°Ÿã ÿπŸÑŸâ ŸÖÿ∑ÿßÿ®ŸÇÿ© ÿ™ÿßÿ±ŸäÿÆ ÿßŸÑÿ£ÿ±ÿ¥ŸäŸÅ
     */
    async fetchOverdueStores() {
      const authStore = useAuthStore();

      // ‚úÖ ÿßŸÑÿÆÿ∑Ÿàÿ© 1: ÿßŸÑÿ≠ÿµŸàŸÑ ÿπŸÑŸâ ÿ¢ÿÆÿ± ÿ™ÿßÿ±ŸäÿÆ ÿ£ÿ±ÿ¥ŸäŸÅ
      const latestArchiveDate = await this._getLatestArchiveDate();

      if (!latestArchiveDate) {
        logger.info('üì≠ No archives found, no overdue to fetch');
        return [];
      }

      logger.info(`üìÖ Latest archive date: ${latestArchiveDate}`);

      // ‚úÖ ÿßŸÑÿÆÿ∑Ÿàÿ© 2: ÿßŸÑÿ≠ÿµŸàŸÑ ÿπŸÑŸâ ÿßŸÑŸÖÿ™ÿ£ÿÆÿ±ÿßÿ™ ÿßŸÑŸÖÿ≠ŸÑŸäÿ©
      const localMetadata = await localforage.getItem('overdue_stores_metadata');
      const localDate = localMetadata?.archive_date || null;
      const localItems = localMetadata?.items || [];

      logger.info(`üìç Local overdue date: ${localDate || 'none'}`);

      // ‚úÖ ÿßŸÑÿÆÿ∑Ÿàÿ© 3: ÿßŸÑŸÖŸÇÿßÿ±ŸÜÿ© ÿßŸÑÿ®ÿ≥Ÿäÿ∑ÿ©
      if (localDate === latestArchiveDate) {
        // ‚úÖ ÿßŸÑÿ™ÿßÿ±ŸäÿÆ ŸÖÿ∑ÿßÿ®ŸÇ - ÿ•ÿ±ÿ¨ÿßÿπ ÿßŸÑŸÖÿ≠ŸÑŸä
        logger.info('‚úÖ Local overdue matches latest archive date - using local');

        // ÿßŸÑÿ™ÿ≠ŸÇŸÇ ŸÖŸÜ ÿßŸÑŸÖÿ≤ÿßŸÖŸÜÿ© ŸÅŸä ÿßŸÑÿÆŸÑŸÅŸäÿ©
        if (!localMetadata.synced_to_cloud && navigator.onLine && authStore.user) {
          this.syncOverdueStoresToCloud(localItems, localDate).catch(err => {
            logger.warn('Background sync failed:', err);
          });
        }

        return localItems;
      }

      // ‚úÖ ÿßŸÑÿÆÿ∑Ÿàÿ© 4: ÿßŸÑÿ™ÿßÿ±ŸäÿÆ ÿ∫Ÿäÿ± ŸÖÿ∑ÿßÿ®ŸÇ ÿ£Ÿà ŸÑÿß ŸäŸàÿ¨ÿØ ŸÖÿ≠ŸÑŸä - ÿ¨ŸÑÿ® ŸÖŸÜ ÿßŸÑÿ≥ÿ≠ÿßÿ®ÿ©
      logger.info('üîÑ Local date does not match or missing - fetching from cloud');

      if (!navigator.onLine || !authStore.user) {
        logger.warn('‚ö†Ô∏è Offline and local date mismatch - returning local (may be outdated)');
        return localItems;
      }

      try {
        const { data: cloudItems, error } = await supabase
          .from('pending_overdue_stores')
          .select('shop, code, net, archive_date')
          .eq('user_id', authStore.user.id)
          .eq('archive_date', latestArchiveDate);

        if (error) throw error;

        if (cloudItems && cloudItems.length > 0) {
          // ÿ≠ŸÅÿ∏ ŸÖÿ≠ŸÑŸäÿßŸã
          await this._saveOverdueWithArchiveDate(cloudItems, latestArchiveDate);

          logger.info(`üì• Fetched ${cloudItems.length} overdue items from cloud`);
          return cloudItems;
        } else {
          // ŸÑÿß ÿ™Ÿàÿ¨ÿØ ŸÖÿ™ÿ£ÿÆÿ±ÿßÿ™ ŸÅŸä ÿßŸÑÿ≥ÿ≠ÿßÿ®ÿ© ŸÑŸáÿ∞ÿß ÿßŸÑÿ™ÿßÿ±ŸäÿÆ
          logger.info('üì≠ No overdue items in cloud for this date');

          // ÿ≠ÿ∞ŸÅ ÿßŸÑŸÖÿ≠ŸÑŸä ÿßŸÑŸÇÿØŸäŸÖ
          await localforage.removeItem('overdue_stores_metadata');

          return [];
        }

      } catch (err) {
        logger.error('‚ùå Failed to fetch from cloud:', err);
        // ŸÅŸä ÿ≠ÿßŸÑÿ© ÿßŸÑÿÆÿ∑ÿ£ÿå ÿ•ÿ±ÿ¨ÿßÿπ ÿßŸÑŸÖÿ≠ŸÑŸä
        return localItems;
      }
    },

    async applyOverdueStores(storesToApply) {
      if (!storesToApply || storesToApply.length === 0) return { addedCount: 0, duplicatesCount: 0 };

      let addedCount = 0;
      let duplicatesCount = 0;

      storesToApply.forEach(overdueStore => {
        const existingRow = this.rows.find(r => r.code && r.code.toString() === overdueStore.code.toString());

        // Count as duplicate for reporting if it already exists
        if (existingRow) {
          duplicatesCount++;
        }

        const overdueAmount = overdueStore.net * -1;

        if (existingRow) {
          // Accumulate the amount (e.g. 1000 + 1000 = 2000)
          existingRow.extra = (parseFloat(existingRow.extra) || 0) + overdueAmount;
          if (overdueStore.net < 0) existingRow.hasOverdue = true;
          else existingRow.hasOverpayment = true;

          existingRow.isOverdueApplied = true; // Mark as applied (Persistent)
          addedCount++;
        } else {
          // Add new row logic...
          if (this.rows.length === 1 && !this.rows[0].shop && !this.rows[0].code) {
            this.rows.pop();
          }
          this.rows.push({
            id: Date.now() + Math.random(),
            shop: overdueStore.shop,
            code: overdueStore.code,
            amount: null,
            extra: overdueAmount,
            collector: null,
            net: 0,
            isImported: false,
            hasOverdue: overdueStore.net < 0,
            hasOverpayment: overdueStore.net > 0,
            isOverdueApplied: true // Mark as applied (Persistent)
          });
          addedCount++;
        }
      });

      const lastRow = this.rows[this.rows.length - 1];
      if (lastRow && (lastRow.shop || lastRow.code || lastRow.amount || lastRow.extra)) {
        this.addRow();
      }

      await this.saveRowsToStorage();
      return { addedCount, duplicatesCount };
    },

    async clearOverdueStores() {
      // 1. Clear both old and new local storage keys
      await localforage.removeItem('overdue_stores');
      await localforage.removeItem('overdue_stores_metadata');

      const authStore = useAuthStore();
      if (authStore.user && navigator.onLine) {
        try {
          await supabase
            .from('pending_overdue_stores')
            .delete()
            .eq('user_id', authStore.user.id);
        } catch (err) {
          logger.error('Error clearing cloud overdue stores:', err);
        }
      }
    },

    /**
     * ÿßÿ≥ÿ™ÿπÿßÿØÿ© ÿ¢ÿÆÿ± ŸÖÿ™ÿ£ÿÆÿ±ÿßÿ™ ŸÖŸÜ ÿßŸÑÿ£ÿ±ÿ¥ŸäŸÅ
     * ŸäŸÇŸàŸÖ ÿ®ÿ≠ÿ∞ŸÅ ÿ¨ŸÖŸäÿπ ÿßŸÑŸÖÿ™ÿ£ÿÆÿ±ÿßÿ™ ÿßŸÑÿ≠ÿßŸÑŸäÿ© ÿ´ŸÖ ÿ¨ŸÑÿ® ÿßŸÑŸÖÿ™ÿ£ÿÆÿ±ÿßÿ™ ŸÖŸÜ ÿ¢ÿÆÿ± ÿ™ÿßÿ±ŸäÿÆ ÿ£ÿ±ÿ¥ŸäŸÅ
     */
    async restoreLatestOverdueFromArchive() {
      logger.info('üîÑ Starting restore latest overdue from archive...');

      try {
        // 1. ÿ≠ÿ∞ŸÅ ÿ¨ŸÖŸäÿπ ÿßŸÑŸÖÿ™ÿ£ÿÆÿ±ÿßÿ™ ÿßŸÑÿ≠ÿßŸÑŸäÿ© ÿ®ÿ¥ŸÉŸÑ ÿ¨ÿ∞ÿ±Ÿä (ŸÖÿ≠ŸÑŸäÿßŸã Ÿàÿ≥ÿ≠ÿßÿ®ŸäÿßŸã)
        logger.info('üóëÔ∏è Clearing all current overdue data...');
        await this.clearOverdueStores();

        // 2. ÿßŸÑÿ≠ÿµŸàŸÑ ÿπŸÑŸâ ÿ¢ÿÆÿ± ÿ™ÿßÿ±ŸäÿÆ ÿ£ÿ±ÿ¥ŸäŸÅ ŸÖŸÜ ÿßŸÑŸÇÿßÿ¶ŸÖÿ© ÿßŸÑŸÖÿ≠ŸÑŸäÿ©
        const archiveStore = useArchiveStore();

        // ÿ™ÿ≠ŸÖŸäŸÑ ÿßŸÑÿ™Ÿàÿßÿ±ŸäÿÆ ÿßŸÑŸÖÿ™ÿßÿ≠ÿ© ÿ•ÿ∞ÿß ŸÑŸÖ ÿ™ŸÉŸÜ ŸÖÿ≠ŸÖŸÑÿ© (ÿ≥ÿ±Ÿäÿπ ÿ¨ÿØÿßŸã ŸÑÿ£ŸÜŸáÿß ŸÖÿ≠ŸÑŸäÿ©)
        if (archiveStore.availableDates.length === 0) {
          await archiveStore.loadAvailableDates(false); // false = don't force cloud fetch
        }

        const latestArchiveDate = archiveStore.availableDates[0]?.value || null;

        if (!latestArchiveDate) {
          logger.warn('‚ö†Ô∏è No archive dates found');
          return {
            success: false,
            message: 'ŸÑÿß ÿ™Ÿàÿ¨ÿØ ÿ™Ÿàÿßÿ±ŸäÿÆ ÿ£ÿ±ÿ¥ŸäŸÅ ŸÖÿ™ÿßÿ≠ÿ©',
            items: []
          };
        }

        logger.info(`üìÖ Latest archive date found (local): ${latestArchiveDate}`);

        // 3. ÿ¨ŸÑÿ® ÿ®ŸäÿßŸÜÿßÿ™ ÿßŸÑÿ£ÿ±ÿ¥ŸäŸÅ ŸÖŸÜ IndexedDB ŸÖÿ®ÿßÿ¥ÿ±ÿ© (ÿ≥ÿ±Ÿäÿπ ÿ¨ÿØÿßŸã)
        const localKey = `${archiveStore.DB_PREFIX}${latestArchiveDate}`;
        const archiveData = await localforage.getItem(localKey);


        if (!archiveData || !Array.isArray(archiveData) || archiveData.length === 0) {
          logger.warn('‚ö†Ô∏è No archive data found locally for this date');
          return {
            success: false,
            message: `ŸÑÿß ÿ™Ÿàÿ¨ÿØ ÿ®ŸäÿßŸÜÿßÿ™ ÿ£ÿ±ÿ¥ŸäŸÅ ŸÖÿ≠ŸÑŸäÿ© ŸÑŸÑÿ™ÿßÿ±ŸäÿÆ ${latestArchiveDate}`,
            items: []
          };
        }

        logger.info(`üì¶ Found ${archiveData.length} rows in local archive`);

        // 4. ÿ≠ÿ≥ÿßÿ® ÿßŸÑŸÖÿ™ÿ£ÿÆÿ±ÿßÿ™ ŸÖŸÜ ÿ®ŸäÿßŸÜÿßÿ™ ÿßŸÑÿ£ÿ±ÿ¥ŸäŸÅ ÿßŸÑŸÖÿ≠ŸÑŸäÿ©
        const overdueItems = archiveData
          .map(row => ({
            shop: row.shop,
            code: row.code,
            net: (parseFloat(row.collector) || 0) - ((parseFloat(row.amount) || 0) + (parseFloat(row.extra) || 0))
          }))
          .filter(item => item.net !== 0); // ŸÅŸÇÿ∑ ÿßŸÑŸÖÿ≠ŸÑÿßÿ™ ÿßŸÑÿ™Ÿä ŸÑÿØŸäŸáÿß ŸÖÿ™ÿ£ÿÆÿ±ÿßÿ™

        if (overdueItems.length === 0) {
          logger.info('üì≠ No overdue items found in archive (all balanced)');
          return {
            success: true,
            message: 'ŸÑÿß ÿ™Ÿàÿ¨ÿØ ŸÖÿ™ÿ£ÿÆÿ±ÿßÿ™ ŸÅŸä ÿßŸÑÿ£ÿ±ÿ¥ŸäŸÅ ŸÑŸáÿ∞ÿß ÿßŸÑÿ™ÿßÿ±ŸäÿÆ (ÿ¨ŸÖŸäÿπ ÿßŸÑŸÖÿ≠ŸÑÿßÿ™ ŸÖÿ™Ÿàÿßÿ≤ŸÜÿ©)',
            items: [],
            archiveDate: latestArchiveDate
          };
        }

        // 5. ÿ≠ŸÅÿ∏ ÿßŸÑŸÖÿ™ÿ£ÿÆÿ±ÿßÿ™ ÿßŸÑŸÖÿ≥ÿ™ÿπÿßÿØÿ© ŸÖÿ≠ŸÑŸäÿßŸã
        await this._saveOverdueWithArchiveDate(overdueItems, latestArchiveDate);

        // 6. ŸÖÿ≤ÿßŸÖŸÜÿ© ŸÖÿπ ÿßŸÑÿ≥ÿ≠ÿßÿ®ÿ© ŸÅŸä ÿßŸÑÿÆŸÑŸÅŸäÿ© (ÿ∫Ÿäÿ± ŸÖÿ≠ÿ∏Ÿàÿ±)
        const authStore = useAuthStore();
        if (navigator.onLine && authStore.user) {
          this.syncOverdueStoresToCloud(overdueItems, latestArchiveDate, true).catch(err => {
            logger.warn('‚ö†Ô∏è Background sync to cloud failed (non-critical):', err);
          });
        }

        logger.info(`‚úÖ Successfully restored ${overdueItems.length} overdue items from local archive ${latestArchiveDate}`);

        return {
          success: true,
          message: `ÿ™ŸÖ ÿßÿ≥ÿ™ÿπÿßÿØÿ© ${overdueItems.length} ŸÖÿ™ÿ£ÿÆÿ±ÿßÿ™ ŸÖŸÜ ÿ™ÿßÿ±ŸäÿÆ ${latestArchiveDate}`,
          items: overdueItems,
          archiveDate: latestArchiveDate
        };

      } catch (error) {
        logger.error('‚ùå Failed to restore overdue from archive:', error);
        return {
          success: false,
          message: 'ÿ≠ÿØÿ´ ÿÆÿ∑ÿ£ ÿ£ÿ´ŸÜÿßÿ° ÿßÿ≥ÿ™ÿπÿßÿØÿ© ÿßŸÑŸÖÿ™ÿ£ÿÆÿ±ÿßÿ™',
          items: []
        };
      }
    },

    async syncOverdueStoresToCloud(items, archiveDate, manualQueue = false) {
      const authStore = useAuthStore();
      if (!authStore.user || !navigator.onLine) {
        if (!manualQueue) {
          // Add to queue if not triggered by queue processor
          await addToSyncQueue({
            type: 'sync_overdue_stores',
            payload: { items, archive_date: archiveDate },
            timestamp: Date.now()
          });
        }
        return;
      }

      if (!items || items.length === 0) return;

      // 1. Prepare data for batch insert
      const userId = authStore.user.id;
      const payload = items.map(item => ({
        user_id: userId,
        shop: item.shop,
        code: String(item.code), // Ensure code is string
        net: item.net,
        archive_date: archiveDate
      }));

      // 2. Clear old pending for this user? No, we upsert based on (user_id, code).
      // Actually, pending_overdue_stores table might need unique constraint on user_id, code.
      // Assuming it has it. If not, we should delete first or use upsert.
      // We will try upsert.

      try {
        const codes = payload.map(p => p.code);

        // A. Delete existing logic
        const chunkSize = 50;
        for (let i = 0; i < codes.length; i += chunkSize) {
          const chunkCodes = codes.slice(i, i + chunkSize);
          await supabase
            .from('pending_overdue_stores')
            .delete()
            .eq('user_id', userId)
            .in('code', chunkCodes);
        }

        // B. Insert new records
        for (let i = 0; i < payload.length; i += chunkSize) {
          const chunk = payload.slice(i, i + chunkSize);
          const { error } = await supabase
            .from('pending_overdue_stores')
            .insert(chunk);

          if (error) throw error;
        }
        logger.info(`‚úÖ Cloud sync overdue success: ${items.length} items`);
      } catch (err) {
        logger.error('‚ùå Cloud sync overdue failed:', err);
        throw err; // Let queue processor handle retry
      }
    },

    async deleteOverdueStores(codes = []) {
      if (!Array.isArray(codes) || codes.length === 0) return;
      try {
        // Support both old format (array) and new format (metadata object)
        const metadata = await localforage.getItem('overdue_stores_metadata');
        let currentItems = [];

        if (metadata && metadata.items) {
          currentItems = metadata.items;
        } else {
          // Fallback to old key for one last time
          currentItems = (await localforage.getItem('overdue_stores')) || [];
        }

        const filtered = currentItems.filter(s => !codes.includes(String(s.code)));

        // Update both if they exist, but primarily the new metadata format
        if (metadata) {
          metadata.items = filtered;
          await localforage.setItem('overdue_stores_metadata', metadata);
        } else if (currentItems.length > 0) {
          // If we only have the old format, we don't migrate here (fetch will handle it), just update old key
          if (filtered.length > 0) await localforage.setItem('overdue_stores', filtered);
          else await localforage.removeItem('overdue_stores');
        }

        // Cloud Delete
        const authStore = useAuthStore();
        if (authStore.user && navigator.onLine) {
          await supabase
            .from('pending_overdue_stores')
            .delete()
            .eq('user_id', authStore.user.id)
            .in('code', codes.map(String));
        }

      } catch (err) {
        logger.error('Error deleting overdue stores:', err);
      }
    },

    async clearAll() {
      await this.resetTable();
      this.searchQuery = '';
      this.currentBalance = 0;
      this.extraLimit = 0;
      this.currentBalance = 0;
      this.extraLimit = 0;
      await removeFromAllCaches('currentBalance');
      await removeFromAllCaches('extraLimit');
      await localforage.removeItem(HARVEST_ROWS_KEY);
      this.isModified = false;
    },

    async clearFields() {
      await this.clearAll();
    },

    async getAccurateDate() {
      return await TimeService.getCairoDate();
    },

    // ... (existing imports)

    // ...

    async archiveTodayData(dateToSave) {
      const collabStore = useCollaborationStore();
      if (collabStore.activeSessionId) {
        throw new Error("ŸÑÿß ŸäŸÖŸÉŸÜŸÉ ÿ£ÿ±ÿ¥ŸÅÿ© ÿ®ŸäÿßŸÜÿßÿ™ ÿ≤ŸÖŸäŸÑÿå Ÿäÿ¨ÿ® ÿ•ŸÜŸáÿßÿ° ÿßŸÑÿ¨ŸÑÿ≥ÿ© ÿ£ŸàŸÑÿßŸã.");
      }
      if (!dateToSave) throw new Error("Date is required for archiving.");

      this.isLoading = true;
      try {
        const authStore = useAuthStore();
        const archiveStore = useArchiveStore();
        if (!authStore.isAuthenticated) throw new Error('Ÿäÿ¨ÿ® ÿ™ÿ≥ÿ¨ŸäŸÑ ÿßŸÑÿØÿÆŸàŸÑ ÿ£ŸàŸÑÿßŸã');

        const validRows = this.rows.filter(r => r.shop || r.code || (parseFloat(r.amount) > 0) || (parseFloat(r.collector) > 0));
        if (validRows.length === 0) return { success: false, message: 'ŸÑÿß ÿ™Ÿàÿ¨ÿØ ÿ®ŸäÿßŸÜÿßÿ™ ÿµÿßŸÑÿ≠ÿ© ŸÑŸÑÿ£ÿ±ÿ¥ŸÅÿ©' };

        const cleanRows = safeDeepClone(validRows).map(row => {
          const amount = parseFloat(row.amount) || 0;
          const extra = parseFloat(row.extra) || 0;
          const collector = parseFloat(row.collector) || 0;
          const net = collector - (amount + extra);
          return { shop: row.shop || '', code: row.code || '', amount, extra, collector, net };
        });

        const localKey = `${archiveStore.DB_PREFIX}${dateToSave}`;
        const dbPayload = {
          user_id: authStore.user.id,
          archive_date: dateToSave,
          data: cleanRows,
        };

        const overdueStores = validRows
          .map(row => ({ ...row, net: (parseFloat(row.collector) || 0) - ((parseFloat(row.amount) || 0) + (parseFloat(row.extra) || 0)) }))
          .filter(row => row.net !== 0)
          .map(row => ({ shop: row.shop, code: row.code, net: row.net }));

        // Safe Save: Wrap Promise.all with a timeout (10s)
        await withTimeout(
          Promise.all([
            localforage.setItem(localKey, cleanRows),
            overdueStores.length > 0
              ? this._saveOverdueWithArchiveDate(overdueStores, dateToSave)
              : Promise.all([
                localforage.removeItem('overdue_stores'),          // ÿ≠ÿ∞ŸÅ ÿßŸÑŸÜÿ∏ÿßŸÖ ÿßŸÑŸÇÿØŸäŸÖ
                localforage.removeItem('overdue_stores_metadata')  // ÿ≠ÿ∞ŸÅ ÿßŸÑŸÜÿ∏ÿßŸÖ ÿßŸÑÿ¨ÿØŸäÿØ
              ])
          ]),
          10000,
          'ÿßŸÜÿ™Ÿáÿ™ ŸÖŸáŸÑÿ© ÿ≠ŸÅÿ∏ ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ (Database Timeout). Ÿäÿ±ÿ¨Ÿâ ÿßŸÑŸÖÿ≠ÿßŸàŸÑÿ© ŸÖÿ±ÿ© ÿ£ÿÆÿ±Ÿâ.'
        );

        // ... fire and forget cloud sync ...
        this._performCloudSync(dbPayload);
        (async () => {
          try {
            if (navigator.onLine) {
              await this.syncOverdueStoresToCloud(overdueStores, dateToSave);

              // ÿ™ÿ≠ÿØŸäÿ´ ÿ≠ÿßŸÑÿ© ÿßŸÑŸÖÿ≤ÿßŸÖŸÜÿ©
              const metadata = await localforage.getItem('overdue_stores_metadata');
              if (metadata) {
                metadata.synced_to_cloud = true;
                await localforage.setItem('overdue_stores_metadata', metadata);
              }
              logger.info('‚úÖ Overdue synced successfully in background');
            } else {
              await addToSyncQueue({
                type: 'sync_overdue_stores',
                payload: { items: overdueStores, archive_date: dateToSave },
                timestamp: Date.now()
              });
              logger.info(`üìå Overdue queued for sync (offline) - Date: ${dateToSave}`);
            }
          } catch (err) {
            logger.warn('‚ö†Ô∏è Background overdue sync failed, adding to queue:', err);
            // Queue attempt
            await addToSyncQueue({
              type: 'sync_overdue_stores',
              payload: { items: overdueStores, archive_date: dateToSave },
              timestamp: Date.now()
            });
          }
        })();

        // Safe Refresh: Wrap loadAvailableDates with timeout (5s) AND catch so it doesn't block success
        try {
          await withTimeout(archiveStore.loadAvailableDates(false), 5000);
        } catch (refreshErr) {
          logger.warn('Archive refresh timed out/failed, but data was saved.', refreshErr);
          // We proceed to return success because the SAVE itself succeeded.
        }

        try {
          const itineraryStore = useItineraryStore();
          // Also simple timeout for itinerary sync just in case
          await withTimeout(itineraryStore.syncFromDashboard(cleanRows), 7000);
        } catch (syncError) {
          logger.error('Failed to sync with itinerary after archiving:', syncError);
          // Do not block the main operation, just log the error
        }

        return { success: true, message: 'ÿ™ŸÖ ÿßŸÑÿ≠ŸÅÿ∏ ÿπŸÑŸâ ÿßŸÑŸáÿßÿ™ŸÅ ÿ®ŸÜÿ¨ÿßÿ≠ÿå Ÿàÿ™ÿ™ŸÖ ÿßŸÑŸÖÿ≤ÿßŸÖŸÜÿ© ÿ≥ÿ≠ÿßÿ®ŸäÿßŸã üíæ' };
      } catch (error) {
        logger.error('üí• Archive Error:', error);
        return { success: false, message: error.message || 'ŸÅÿ¥ŸÑ ŸÅŸä ÿßŸÑÿ£ÿ±ÿ¥ŸÅÿ©' };
      } finally {
        this.isLoading = false;
      }
    },

    async _performCloudSync(dbPayload) {
      // ÿØÿßÿ¶ŸÖÿßŸã ŸÜÿ≥ÿ™ÿÆÿØŸÖ ÿßŸÑÿ∑ÿßÿ®Ÿàÿ± ŸÑÿ∂ŸÖÿßŸÜ ÿπÿØŸÖ ÿ™ÿπŸÑŸäŸÇ ÿßŸÑŸàÿßÿ¨Ÿáÿ© Ÿàÿ≠ŸÅÿ∏ ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™
      // ÿ≥ŸäŸÇŸàŸÖ ÿßŸÑÿ∑ÿßÿ®Ÿàÿ± ÿ®ŸÖÿπÿßŸÑÿ¨ÿ© ÿßŸÑÿ∑ŸÑÿ® ŸÅŸä ÿßŸÑÿÆŸÑŸÅŸäÿ© ŸÅŸàÿ±ÿßŸã ÿ•ÿ∞ÿß ŸÉÿßŸÜ ŸáŸÜÿßŸÉ ÿ•ŸÜÿ™ÿ±ŸÜÿ™
      await addToSyncQueue({ type: 'daily_archive', payload: dbPayload });
      return 'queued';
    },

    parseRawDataToRows(rawData) {
      if (!rawData) return [];
      return rawData.split('\n').map((line, index) => {
        const trimmedLine = line.trim();
        if (!trimmedLine || trimmedLine.includes("ÿßŸÑŸÖÿ≥ŸÑÿ≥ŸÑ")) return null;
        const parts = trimmedLine.split("\t");
        if (parts.length < 2) return null;
        let shopName = parts[1].trim();
        let code = parts[2] ? parts[2].trim() : "";
        const match = shopName.match(/(.+?):\s*(\d+)/);
        if (match) {
          shopName = match[1].trim();
          code = match[2].trim();
        }
        const transferAmount = parseFloat(parts[3]?.replace(/,/g, '') || 0);
        if (transferAmount === 0) return null;
        return {
          id: Date.now() + index,
          serial: index + 1,
          shop: shopName,
          code: code,
          amount: transferAmount,
          extra: null, collector: null, net: 0 - transferAmount,
          isImported: true, hasOverdue: false, hasOverpayment: false
        };
      }).filter(Boolean);
    },

    async loadDataFromStorage() {
      const newData = await getLocalStorageCache("harvestData");
      if (newData) {
        const newRows = this.parseRawDataToRows(newData);
        if (newRows.length > 0) {
          this.rows = newRows;
          await this.addRow();
          await removeFromAllCaches("harvestData");
          await this.saveRowsToStorage();
          return true;
        }
      }
      return false;
    },

    addRowWithData(newRowData) {
      if (!newRowData || !newRowData.code) return;
      if (this.rows.length === 0 || (this.rows.length === 1 && !this.rows[0].code && !this.rows[0].shop)) {
        this.rows = [];
      }
      this.rows.push({
        id: Date.now() + Math.random(),
        shop: newRowData.shop || '',
        code: newRowData.code || '',
        amount: newRowData.amount || null,
        extra: null, collector: null, net: 0,
        isImported: true, hasOverdue: false, hasOverpayment: false
      });
    },

    async addRow() {
      this.rows.push({
        id: Date.now() + Math.random(),
        serial: this.rows.length + 1,
        shop: '', code: '', amount: '', extra: '', collector: '', net: 0,
        isImported: false, hasOverdue: false, hasOverpayment: false
      });
      await this.saveRowsToStorage();
    },

    async setMasterLimit(limit) {
      this.masterLimit = parseFloat(limit) || 0;
      await setLocalStorageCache('masterLimit', this.masterLimit.toString());
      this.saveRowsToStorage();
    },

    async loadMasterLimit() {
      const limit = await getLocalStorageCache('masterLimit');
      this.masterLimit = limit !== null ? parseFloat(limit) : 100000;
    },

    async setExtraLimit(limit) {
      this.extraLimit = parseFloat(limit) || 0;
      await setLocalStorageCache('extraLimit', this.extraLimit.toString());
      this.saveRowsToStorage();
    },

    async loadExtraLimit() {
      const limit = await getLocalStorageCache('extraLimit');
      if (limit) this.extraLimit = parseFloat(limit);
    },

    async setCurrentBalance(balance) {
      this.currentBalance = parseFloat(balance) || 0;
      await setLocalStorageCache('currentBalance', this.currentBalance.toString());
      this.saveRowsToStorage();
    },

    formatNumber(num) {
      return new Intl.NumberFormat('en-US', { minimumFractionDigits: 0, maximumFractionDigits: 2 }).format(num || 0);
    },

    sortRowsByItineraryProfile(shopsOrder) {
      if (!shopsOrder || shopsOrder.length === 0) return;
      const orderMap = new Map(shopsOrder.map((code, index) => [String(code), index]));
      this.rows.sort((a, b) => {
        const orderA = orderMap.has(String(a.code)) ? orderMap.get(String(a.code)) : Infinity;
        const orderB = orderMap.has(String(b.code)) ? orderMap.get(String(b.code)) : Infinity;
        return orderA - orderB;
      });
      this.saveRowsToStorage();
    }
  }
});